{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqAQKKzVSGoQ1e3isUf9QB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"J4qLHfLn9bDU"},"outputs":[],"source":["### ROC curve\n","\n","from sklearn.metrics import roc_curve\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","import numpy as np \n","import itertools \n","\n","def plot_roc_curve(fper, tper):\n","    plt.plot(fper, tper, color='red', label='ROC')\n","    plt.plot([0, 1], [0, 1], color='green', linestyle='--')\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic Curve')\n","    plt.legend()\n","    plt.show()\n","    \n","\n","### confusion matrix \n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n","from sklearn.preprocessing import Binarizer\n","def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):\n","    #thresholds list 객체 내의 값을 iteration 하면서 평가 수행\n","\n","    result = []\n","    for custom_threshold in thresholds:\n","        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n","        custom_predict = binarizer.transform(pred_proba_c1)\n","        \n","        result_list =  get_clf_eval(y_test, custom_predict) + [custom_threshold]\n","        result.append(result_list)\n","    return result \n","def get_clf_eval(y_test, pred):\n","    confusion = confusion_matrix(y_test, pred)\n","    #accuracy = accuracy_score(y_test, pred)\n","    #precision = precision_score(y_test, pred)\n","    #recall = recall_score(y_test, pred)\n","    tp = confusion[1][1]\n","    fn = confusion[1][0]\n","    fp = confusion[0][1]\n","    tn = confusion[0][0]\n","    specificity = tn/(fp+tn)\n","    recall = tp/(tp+fn)\n","    precision = tp/(tp+fp)\n","    accuracy = (tp+tn)/(tp+tn+fp+fn)\n","    # F1 스코어 추가\n","    f1 = f1_score(y_test, pred)\n","    # F1 score print 추가\n","\n","    return [accuracy, precision, recall, specificity, f1]\n","\n","def acc_graph(history):\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['Train', 'Val'], loc='upper left')\n","    plt.show()\n","\n","def loss_graph(history):\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('Model loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend(['Train', 'Val'], loc='upper left')\n","    plt.show()"]},{"cell_type":"code","source":[],"metadata":{"id":"hp1664-T_dwZ"},"execution_count":null,"outputs":[]}]}